{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.gridspec as gridspec\n",
    "from string import ascii_uppercase\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "MODEL_DICT = 'model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Auxiliary functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def show(crop_characters: list, cmap: str = \"gray\") -> None:\n",
    "    \"\"\"Displays a list of images side-by-side\"\"\"\n",
    "\n",
    "    if len(crop_characters) != 0:\n",
    "        fig = plt.figure(figsize=(10,5), constrained_layout=True)\n",
    "        grid = gridspec.GridSpec(ncols=len(crop_characters),nrows=1,figure=fig)\n",
    "\n",
    "        for i in range(len(crop_characters)):\n",
    "            fig.add_subplot(grid[i])\n",
    "            plt.axis(False)\n",
    "            plt.imshow(crop_characters[i], cmap=cmap)\n",
    "\n",
    "def get_data(path: str) -> list:\n",
    "    \"\"\"Returns an iterator with paths to each image to be detected\"\"\"\n",
    "\n",
    "    imgs = os.listdir(path)\n",
    "    return sorted([f\"{path}/{img}\" for img in imgs])\n",
    "\n",
    "def box_of_points(points: list) -> tuple:\n",
    "    \"\"\"Returns the biggest box from a series of points. Returns x_max, x_min, y_max, y_min\"\"\"\n",
    "\n",
    "    return max(points,key=lambda x: x[0])[0], min(points,key=lambda x: x[0])[0], \\\n",
    "           max(points,key=lambda x: x[1])[1], min(points,key=lambda x: x[1])[1]\n",
    "\n",
    "def sort_contours(cnts, reverse = False):\n",
    "    i = 0\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    cnts, _ = zip(*sorted(zip(cnts, bounding_boxes),\n",
    "                          key=lambda b: b[1][i], reverse=reverse))\n",
    "    return cnts\n",
    "\n",
    "def set_angle(angle: float):\n",
    "    \"\"\"Converts any angle to +-45 degrees\"\"\"\n",
    "\n",
    "    if -45 < angle < 45:\n",
    "        rotation = angle\n",
    "    elif angle < -45:\n",
    "        rotation = 90 + angle\n",
    "    else:\n",
    "        rotation = 90 - angle\n",
    "\n",
    "    return rotation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = get_data(\"data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plate detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class PlateLocator(object):\n",
    "\n",
    "    __slots__ = ['size', 'kernel_size', 'sigma_color', 'sigma_space', 'keep_hulls', 'wh_ratio', 'digit_size']\n",
    "\n",
    "    def __init__(self, size:tuple = (620, 480), kernel_size:tuple = (5, 5), sigma_color: int = 200,\n",
    "                 sigma_space:int = 150, keep_hulls:int = 10, wh_ratio:tuple = (1.5, 3.5), digit_size: tuple = (30, 60)) -> None:\n",
    "\n",
    "        self.size = size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma_color = sigma_color\n",
    "        self.sigma_space = sigma_space\n",
    "        self.keep_hulls = keep_hulls\n",
    "        self.wh_ratio = wh_ratio\n",
    "        self.digit_size = digit_size\n",
    "\n",
    "    def process(self, image: str, display: bool = False):\n",
    "        processed, original = self._preprocess(image)\n",
    "        hulls = self._hulls(processed)\n",
    "\n",
    "        plates = []\n",
    "\n",
    "        for candidate in hulls:\n",
    "            valid, plate = self._evaluate_candidate(candidate, original)\n",
    "            if valid:\n",
    "                candidates, _, _ = plate\n",
    "                plates.append(candidates)\n",
    "\n",
    "        if display: show([processed, original]); show(plates)\n",
    "\n",
    "        return plates\n",
    "\n",
    "    def numbers(self, candidate: np.ndarray, display: bool = False):\n",
    "        image_res = cv2.cvtColor(candidate, cv2.COLOR_BGR2GRAY)\n",
    "        image =  cv2.threshold(image_res, 110, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "        output = cv2.connectedComponentsWithStats(image, 4, cv2.CV_32S)\n",
    "\n",
    "        num_labels, _, stats, _ = output\n",
    "\n",
    "        numbs = list()\n",
    "\n",
    "        if display:\n",
    "            roi = candidate.copy()\n",
    "            background = 255 * image.copy().astype(np.int8)\n",
    "\n",
    "        for i in range(num_labels):\n",
    "            x = stats[i, cv2.CC_STAT_LEFT]\n",
    "            y = stats[i, cv2.CC_STAT_TOP]\n",
    "            w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "            h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "            area = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "            if display:\n",
    "                cv2.rectangle(roi, (x-1, y-1), (x+w+1, y+h+1), (100, 100, 0), 1)\n",
    "\n",
    "            # Remove labels that are too small or have points outside the candidate\n",
    "            if x > 1 and y > 1 and area > 5 and h > w and x+w < candidate.shape[1] and y+h < candidate.shape[0]:\n",
    "                numb = image[y-1:y+h+1, x-1:x+w+1]\n",
    "                numb = cv2.resize(numb, self.digit_size, cv2.INTER_NEAREST)\n",
    "                numbs.append((numb, x))\n",
    "\n",
    "                if display:\n",
    "                    cv2.rectangle(roi, (x-1, y-1), (x+w+1, y+h+1), (250, 0, 0), 1)\n",
    "                    cv2.rectangle(background, (x-1, y-1), (x+w+1, y+h+1), (255, 255, 255), 1)\n",
    "\n",
    "        if display and len(numbs) > 6: show([roi, background]); show([x[0] for x in sorted(numbs, key=lambda x: x[1])])\n",
    "\n",
    "        return [x[0] for x in sorted(numbs, key=lambda x: x[1])]\n",
    "\n",
    "    def get_dataset(self, data_folder: list, total: int = -1):\n",
    "        cooked_data = list()\n",
    "\n",
    "        for img in data_folder[:total]:\n",
    "            cooked_data.append([self.numbers(area) for area in self.process(img) if len(self.numbers(area)) > 6])\n",
    "\n",
    "        print(f\"Loaded {len(cooked_data)} image(s)\")\n",
    "        return cooked_data\n",
    "\n",
    "    def _preprocess(self,filepath: str):\n",
    "        image = cv2.imread(filepath)\n",
    "        image = cv2.resize(image, self.size)\n",
    "        image2 = cv2.bilateralFilter(image.copy(), self.kernel_size[0], self.sigma_color ,self.sigma_space)\n",
    "        image_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "        return cv2.dilate(cv2.Canny(image_gray, 0, 255), np.ones((3, 2), np.uint8)), cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def _hulls(self, image: np.ndarray = None):\n",
    "        contours = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = imutils.grab_contours(contours)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:self.keep_hulls]\n",
    "\n",
    "        return [cv2.convexHull(contour) for contour in contours]\n",
    "\n",
    "    def _evaluate_candidate(self, candidate, image: np.ndarray):\n",
    "        rect = cv2.minAreaRect(candidate)\n",
    "        box = np.int0(cv2.boxPoints(rect))\n",
    "        points = box_of_points(box)\n",
    "\n",
    "        if all([x > 0 for x in [point for point in points]]):\n",
    "            x_0, x_1, y_0, y_1 = points\n",
    "            w,h = y_0-y_1 , x_0-x_1\n",
    "            if self.wh_ratio[0] < h/w < self.wh_ratio[1]:\n",
    "                plate = image[y_1:y_0, x_1:x_0]\n",
    "                return True, (plate, rect[2],rect[1]) # plate , angle, w/h\n",
    "\n",
    "        return False, None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Letter recognition network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(64)\n",
    "        self.max_p_1 = F.max_pool2d\n",
    "        self.activation_1 = F.relu\n",
    "        self.conv1_drop = nn.Dropout2d()\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(128)\n",
    "        self.max_p_2 = F.max_pool2d\n",
    "        self.activation_2 = F.relu\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(7680, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 35) # Should be 37: 36 letters + numbers and the extra for non recognized chars\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = self.conv1_drop(self.activation_1( self.max_p_1 ( self.conv1_bn ( self.conv1(x)), 2)))\n",
    "        x = self.conv2_drop(self.activation_2( self.max_p_2 ( self.conv2_bn ( self.conv2(x)), 2)))\n",
    "        x =  x.reshape(batch, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "def get_model() -> nn.Module:\n",
    "    model = BinaryClassifier()\n",
    "    model.load_state_dict(torch.load(MODEL_DICT))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 image(s)\n",
      "['0', 'K', '0', '0', 'K', 'K', 'K', '0', '0', '0', '0']\n",
      "['K', 'K', '7', 'K', 'K', '3', '0', '0']\n",
      "['0', 'W', 'W', '0', '0', '0', '0', '0']\n",
      "['K', 'K', 'K', 'K', 'K', '0', 'A', '0']\n",
      "['K', 'K', 'K', 'K', 'K', '0', '0', '0']\n",
      "['K', '0', '0', 'W', 'K', 'K', '0']\n",
      "['0', 'K', '0', '0', 'K', '0', '0', '0', 'K', '0', '0']\n",
      "['K', '0', '3', 'W', '0', '3', '0']\n"
     ]
    }
   ],
   "source": [
    "locator = PlateLocator()\n",
    "model = get_model()\n",
    "dataset = locator.get_dataset(get_data('data'), 5)\n",
    "idx_to_letters = {x: y for x, y in enumerate(ascii_uppercase + '0123456789')}\n",
    "\n",
    "for element in dataset:\n",
    "    for detection in element:\n",
    "        # This generates the tensor of each group of N numbers with size [N, 1, 60, 30]\n",
    "        in_ = torch.unsqueeze(torch.stack([torch.from_numpy(number) for number in detection]), 1)\n",
    "\n",
    "        out = model(in_.float()) # Weight type is FloatTensor, in_ in ByteTensor?\n",
    "        letters = torch.argmax(out, 1).tolist() # dict cannot tensor(), should be dim 1, 0 is the output of\n",
    "        final = [idx_to_letters[x] for x in letters]\n",
    "        print(final) # Results are wrong for img size, I guess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "906d6cb69cdea5abcae2864bdb4d231ea3c18afe6b60fab0cc086da9036d66a7"
  },
  "kernelspec": {
   "name": "psiv",
   "language": "python",
   "display_name": "PSIV"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}